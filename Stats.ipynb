{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT : Mammogram Classification Using CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET: THE MIAS-MAMMOGRAPHY DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFORMATION:\n",
    "\n",
    "This file lists the films in the MIAS database and provides     \n",
    "appropriate details as follows:\n",
    "\n",
    "1st column: MIAS database reference number.\n",
    "\n",
    "2nd column: Character of background tissue: \n",
    "                F - Fatty \n",
    "                G - Fatty-glandular\n",
    "                D - Dense-glandular\n",
    "\n",
    "3rd column: Class of abnormality present:\n",
    "                CALC - Calcification\n",
    "                CIRC - Well-defined/circumscribed masses\n",
    "                SPIC - Spiculated masses\n",
    "                MISC - Other, ill-defined masses\n",
    "                ARCH - Architectural distortion\n",
    "                ASYM - Asymmetry\n",
    "                NORM - Normal\n",
    "\n",
    "4th column: Severity of abnormality;\n",
    "                B - Benign\n",
    "                M - Malignant\n",
    "                \n",
    "5th,6th columns: x,y image-coordinates of centre of abnormality.\n",
    "\n",
    "7th column: Approximate radius (in pixels) of a circle enclosing\n",
    "            the abnormality.\n",
    "            \n",
    "NOTES\n",
    "\n",
    "1- The list is arranged in pairs of films, where each pair \n",
    "   represents the left (even filename numbers) and right mammograms\n",
    "   (odd filename numbers) of a single patient.\n",
    "   \n",
    "2- The size of ALL the images is 1024 pixels x 1024 pixels. The images\n",
    "   have been centered in the matrix.  \n",
    "\n",
    "3- When calcifications are present, centre locations and radii \n",
    "   apply to clusters rather than individual calcifications.\n",
    "   Coordinate system origin is the bottom-left corner.\n",
    "\n",
    "4- In some cases calcifications are widely distributed throughout\n",
    "   the image rather than concentrated at a single site. In these\n",
    "   cases centre locations and radii are inappropriate and have\n",
    "   been omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system related\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "# import custom modules\n",
    "from modules import helpers as hp\n",
    "from modules import mammoscan as ms\n",
    "\n",
    "# path manipulation\n",
    "from pathlib import Path\n",
    "\n",
    "# regex\n",
    "import re\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "# data manipulation / preparation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# image manipulation\n",
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the scans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bg</th>\n",
       "      <th>ab_class</th>\n",
       "      <th>severity</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>radius</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refnum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mdb001</th>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>535.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdb002</th>\n",
       "      <td>G</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>522.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdb003</th>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdb004</th>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdb005</th>\n",
       "      <td>F</td>\n",
       "      <td>CIRC</td>\n",
       "      <td>B</td>\n",
       "      <td>477.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdb318</th>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdb319</th>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdb320</th>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdb321</th>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdb322</th>\n",
       "      <td>D</td>\n",
       "      <td>NORM</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bg ab_class severity      x      y  radius\n",
       "refnum                                           \n",
       "mdb001  G     CIRC        B  535.0  425.0   197.0\n",
       "mdb002  G     CIRC        B  522.0  280.0    69.0\n",
       "mdb003  D     NORM        A    NaN    NaN     NaN\n",
       "mdb004  D     NORM        A    NaN    NaN     NaN\n",
       "mdb005  F     CIRC        B  477.0  133.0    30.0\n",
       "...    ..      ...      ...    ...    ...     ...\n",
       "mdb318  D     NORM        A    NaN    NaN     NaN\n",
       "mdb319  D     NORM        A    NaN    NaN     NaN\n",
       "mdb320  D     NORM        A    NaN    NaN     NaN\n",
       "mdb321  D     NORM        A    NaN    NaN     NaN\n",
       "mdb322  D     NORM        A    NaN    NaN     NaN\n",
       "\n",
       "[319 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mias = hp.create_mias_dataset('scan_file_data.txt')\n",
    "mias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Data Preparation / Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process takes the original images (1024x1024) and generates rotated and mirrored subsamples of them. \n",
    "\n",
    "The subsamples generated by this process have size (48x48) and rotated versions by 0, 90, 180, 270 degrees.\n",
    "\n",
    "There also are top/bottom and right/left mirrored versions of the original images.\n",
    "\n",
    "Originally, the clean dataset has 319 images. \n",
    "\n",
    "The transformation process produces 3828 images. \n",
    "\n",
    "That is to say that for each image, 12 new images are created or a 1200% increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mias = hp.generate_subsamples('../all-mias/', mias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NORM class, which accounts for the scans with no abnormalities, stands for 64.8% of the scan samples. Its severity was defined as 'A' and it happens during the creation of the mias dataframe.\n",
    "\n",
    "There is also a slight difference between Malign (M) and Benign (B) samples in all classes\n",
    "\n",
    "The strategy to atenuate such disparity is to randomly remove whichever class is predominant (either M or N) so that we can have a balanced set. Classes to be balanced prior to be tested to ensure randomness.\n",
    "\n",
    "As for the NORM class, it will reduced, also randomly, to the average of the samples for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ab_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f1c0298cc5cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ab_class\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseverity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   6509\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6511\u001b[1;33m         return DataFrameGroupBy(\n\u001b[0m\u001b[0;32m   6512\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6513\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[0;32m    526\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    779\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ab_class'"
     ]
    }
   ],
   "source": [
    "mias.groupby([\"ab_class\"]).severity.value_counts() / len(mias.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ab_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-138eb32b0b41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m mias.groupby(['ab_class', 'severity']).size().unstack().plot(kind='bar', \n\u001b[0m\u001b[0;32m      2\u001b[0m                                                                \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                                \u001b[0mxlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Abnormality Class'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                                \u001b[0mylabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SCANS'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                                title='SEVERITY BY CLASS');\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   6509\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6511\u001b[1;33m         return DataFrameGroupBy(\n\u001b[0m\u001b[0;32m   6512\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6513\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[0;32m    526\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    779\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 781\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    782\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ab_class'"
     ]
    }
   ],
   "source": [
    "mias.groupby(['ab_class', 'severity']).size().unstack().plot(kind='bar', \n",
    "                                                               figsize=(10, 8), \n",
    "                                                               xlabel='Abnormality Class', \n",
    "                                                               ylabel='SCANS',\n",
    "                                                               title='SEVERITY BY CLASS');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abnormalities only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mias[mias.ab_class != 'NORM'].groupby(['ab_class', 'severity']).size().unstack().plot(kind='bar', \n",
    "                                                                                      stacked=True, \n",
    "                                                                                      figsize=(10, 8), \n",
    "                                                                                      xlabel='ABNORMALITIES ONLY', \n",
    "                                                                                      ylabel='Percentage',\n",
    "                                                                                      title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset balancing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcifications before balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ab_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4e0c16f8dfaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalcifications_unbalanced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmias\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mab_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'CALC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcalcifications_unbalanced\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseverity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ab_class'"
     ]
    }
   ],
   "source": [
    "calcifications_unbalanced = mias[mias.ab_class == 'CALC']\n",
    "\n",
    "calcifications_unbalanced.severity.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcifications after balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcifications_balanced = hp.balance_by_severity(mias, 'CALC')\n",
    "\n",
    "calcifications_balanced.severity.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Results Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = hp.create_final_results_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR CALCIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ab_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e8585735fff2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalcifications\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbalance_by_severity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CALC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcalcifications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PythonPractice\\D270\\modules\\helpers.py\u001b[0m in \u001b[0;36mbalance_by_severity\u001b[1;34m(df, ab_class)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mab_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mab_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[0msev_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mab_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mab_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseverity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[0mn_benign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msev_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0mn_malign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msev_counts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'M'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ab_class'"
     ]
    }
   ],
   "source": [
    "calcifications = hp.balance_by_severity(mias, 'CALC')\n",
    "calcifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calcifications' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-11c914fa60ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcalcifications\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalcifications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcalcifications\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'calcifications' is not defined"
     ]
    }
   ],
   "source": [
    "calcifications = calcifications.sample(len(calcifications), replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "# train data\n",
    "train_data = data_generator.flow_from_dataframe(calcifications, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "\n",
    "# test data\n",
    "test_data = data_generator.flow_from_dataframe(calcifications, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_calc = Sequential()\n",
    "# first layer\n",
    "cnn_calc.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "cnn_calc.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "cnn_calc.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn_calc.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "cnn_calc.add(MaxPool2D(pool_size=(2, 2)))\n",
    "cnn_calc.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "cnn_calc.add(Dense(64, activation='relu'))\n",
    "cnn_calc.add(Dropout(0.25))\n",
    "# flattening results\n",
    "cnn_calc.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "cnn_calc.add(Dense(2, activation='softmax'))\n",
    "# print summary\n",
    "cnn_calc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(cnn_calc, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(0.001)\n",
    "cnn_calc.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=10_000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = cnn_calc.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = cnn_calc.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = cnn_calc.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                            hist.history['val_accuracy'], \n",
    "                            hist.history['loss'], \n",
    "                            hist.history['val_loss'])\n",
    "\n",
    "# enter data to the final results dataframe\n",
    "results_calc = classification_report(expected, predicted, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_malignant = results_calc['1']\n",
    "calc_malignant\n",
    "final_results.loc['calcifications'] = (accuracy,\n",
    "                                       calc_malignant['precision'], \n",
    "                                       calc_malignant['recall'], \n",
    "                                       calc_malignant['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "wrong_predictions = []\n",
    "images = calcifications.p_matrix\n",
    "predictions = cnn_calc.predict(test_data)\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = calcifications.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=5, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {calcifications.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR MASSES (FULL BALANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "circ_balanced = hp.balance_by_severity(mias, 'CIRC')\n",
    "spic_balanced = hp.balance_by_severity(mias, 'SPIC')\n",
    "misc_balanced = hp.balance_by_severity(mias, 'MISC')\n",
    "# shuffle using the length of the smallest sample (CIRC)\n",
    "circ_balanced = circ_balanced.sample(len(circ_balanced), replace=False)\n",
    "spic_balanced = spic_balanced.sample(len(circ_balanced), replace=False)\n",
    "misc_balanced = misc_balanced.sample(len(circ_balanced), replace=False)\n",
    "# create new dataframe for the masses only\n",
    "masses_balanced = pd.concat([circ_balanced, spic_balanced])\n",
    "masses_balanced = pd.concat([masses_balanced, misc_balanced])\n",
    "# masses dataset\n",
    "masses_balanced = masses_balanced.sample(len(masses_balanced), replace=False)\n",
    "masses_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_balanced.groupby('ab_class').severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_balanced.groupby(['ab_class', 'severity']).severity.size().unstack().plot(kind='bar', \n",
    "                                                                      stacked=True, \n",
    "                                                                      figsize=(10, 8), \n",
    "                                                                      xlabel='Abnormality Class', \n",
    "                                                                      ylabel='Percentage',\n",
    "                                                                      title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "train_data = data_generator.flow_from_dataframe(masses_balanced, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "test_data = data_generator.flow_from_dataframe(masses_balanced, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_cnn = Sequential()\n",
    "# first layer\n",
    "mass_cnn.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "mass_cnn.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "mass_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "mass_cnn.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "mass_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "mass_cnn.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "mass_cnn.add(Dense(64, activation='relu'))\n",
    "mass_cnn.add(Dropout(0.25))\n",
    "# flattening results\n",
    "mass_cnn.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "mass_cnn.add(Dense(2, activation='softmax'))\n",
    "# print summary\n",
    "mass_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mass_cnn, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set optmizer and learning rate\n",
    "adam = Adam(0.001)\n",
    "mass_cnn.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=10_000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = mass_cnn.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = mass_cnn.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = mass_cnn.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                               hist.history['val_accuracy'], \n",
    "                               hist.history['loss'], \n",
    "                               hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter data to the final results dataframe\n",
    "results_mass = classification_report(expected, predicted, output_dict=True)\n",
    "# add entry to the final_results\n",
    "mass_malignant = results_mass['1']\n",
    "mass_malignant\n",
    "final_results.loc['masses_full_bal'] = (accuracy, \n",
    "                                       mass_malignant['precision'], \n",
    "                                       mass_malignant['recall'], \n",
    "                                       mass_malignant['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "predictions = mass_cnn.predict(test_data)\n",
    "\n",
    "# check the probabilities for the first sample\n",
    "for index, probability in enumerate(predictions[0]):\n",
    "    print(f'{index}: {probability:.10%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = masses_balanced.p_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = masses_balanced.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=3, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {masses_balanced.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR MASSES (CLASS BALANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "circ_balanced = hp.balance_by_severity(mias, 'CIRC')\n",
    "spic_balanced = hp.balance_by_severity(mias, 'SPIC')\n",
    "misc_balanced = hp.balance_by_severity(mias, 'MISC')\n",
    "# shuffle using the length of the smallest sample (CIRC)\n",
    "circ_balanced = circ_balanced.sample(len(circ_balanced), replace=False)\n",
    "spic_balanced = spic_balanced.sample(len(spic_balanced), replace=False)\n",
    "misc_balanced = misc_balanced.sample(len(misc_balanced), replace=False)\n",
    "# create new dataframe for the masses only\n",
    "masses_balanced = pd.concat([circ_balanced, spic_balanced])\n",
    "masses_balanced = pd.concat([masses_balanced, misc_balanced])\n",
    "# masses dataset\n",
    "masses_balanced = masses_balanced.sample(len(masses_balanced), replace=False)\n",
    "masses_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_balanced.groupby('ab_class').severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_balanced.groupby(['ab_class', 'severity']).severity.size().unstack().plot(kind='bar', \n",
    "                                                                      stacked=True, \n",
    "                                                                      figsize=(10, 8), \n",
    "                                                                      xlabel='Abnormality Class', \n",
    "                                                                      ylabel='Percentage',\n",
    "                                                                      title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "train_data = data_generator.flow_from_dataframe(masses_balanced, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "test_data = data_generator.flow_from_dataframe(masses_balanced, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_cnn = Sequential()\n",
    "# first layer\n",
    "mass_cnn.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "mass_cnn.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "mass_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "mass_cnn.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "mass_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "mass_cnn.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "mass_cnn.add(Dense(64, activation='relu'))\n",
    "mass_cnn.add(Dropout(0.25))\n",
    "# flattening results\n",
    "mass_cnn.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "mass_cnn.add(Dense(2, activation='softmax'))\n",
    "# print summary\n",
    "mass_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mass_cnn, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set optmizer and learning rate\n",
    "adam = Adam(0.001)\n",
    "mass_cnn.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=10_000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = mass_cnn.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = mass_cnn.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = mass_cnn.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                               hist.history['val_accuracy'], \n",
    "                               hist.history['loss'], \n",
    "                               hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter data to the final results dataframe\n",
    "results_mass = classification_report(expected, predicted, output_dict=True)\n",
    "# add entry to the final_results\n",
    "mass_malignant = results_mass['1']\n",
    "mass_malignant\n",
    "final_results.loc['masses_bal'] = (accuracy,\n",
    "                                   mass_malignant['precision'], \n",
    "                                   mass_malignant['recall'], \n",
    "                                   mass_malignant['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "predictions = mass_cnn.predict(test_data)\n",
    "\n",
    "# check the probabilities for the first sample\n",
    "for index, probability in enumerate(predictions[0]):\n",
    "    print(f'{index}: {probability:.10%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = masses_balanced.p_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = masses_balanced.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=3, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {masses_balanced.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR ALL CLASSES (FULLY BALANCED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_full = hp.full_balance_df_by_severity(mias)\n",
    "all_mias_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_full.groupby('ab_class').severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_full.groupby(['ab_class', 'severity']).size().unstack().plot(kind='bar', \n",
    "                                                              stacked=True, \n",
    "                                                              figsize=(10, 8), \n",
    "                                                              xlabel='ABNORMALITIES ONLY', \n",
    "                                                              ylabel='Percentage',\n",
    "                                                              title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "train_data = data_generator.flow_from_dataframe(all_mias_full, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "test_data = data_generator.flow_from_dataframe(all_mias_full, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias = Sequential()\n",
    "# first layer\n",
    "all_mias.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "all_mias.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "all_mias.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "all_mias.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "all_mias.add(MaxPool2D(pool_size=(2, 2)))\n",
    "all_mias.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "all_mias.add(Dense(64, activation='relu'))\n",
    "all_mias.add(Dropout(0.25))\n",
    "# flattening results\n",
    "all_mias.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "all_mias.add(Dense(3, activation='softmax'))\n",
    "# print summary\n",
    "all_mias.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(all_mias, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set optmizer and learning rate\n",
    "adam = Adam(0.001)\n",
    "all_mias.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=10_000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = all_mias.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = all_mias.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = all_mias.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                               hist.history['val_accuracy'], \n",
    "                               hist.history['loss'], \n",
    "                               hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter data to the final results dataframe\n",
    "results_all_mias = classification_report(expected, predicted, output_dict=True)\n",
    "# add entry to the final_results\n",
    "all_mias_malignant = results_all_mias['1']\n",
    "all_mias_malignant\n",
    "final_results.loc['all_full_bal'] = (accuracy,\n",
    "                                     all_mias_malignant['precision'], \n",
    "                                     all_mias_malignant['recall'], \n",
    "                                     all_mias_malignant['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "predictions = all_mias.predict(test_data)\n",
    "\n",
    "# check the probabilities for the first sample\n",
    "for index, probability in enumerate(predictions[0]):\n",
    "    print(f'{index}: {probability:.10%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = all_mias_full.p_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "    # create something to keep the same index from calcifications_balanced\n",
    "    # and wrong predictions\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_mias_full.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=5, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {all_mias_full.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR ALL CLASSES (CLASS BALANCED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_bal = hp.balance_df_by_severity(mias)\n",
    "all_mias_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_bal.groupby('ab_class').severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_bal.groupby(['ab_class', 'severity']).size().unstack().plot(kind='bar', \n",
    "                                                              stacked=True, \n",
    "                                                              figsize=(10, 8), \n",
    "                                                              xlabel='ABNORMALITIES ONLY', \n",
    "                                                              ylabel='Percentage',\n",
    "                                                              title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "train_data = data_generator.flow_from_dataframe(all_mias_bal, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "test_data = data_generator.flow_from_dataframe(all_mias_bal, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias2 = Sequential()\n",
    "# first layer\n",
    "all_mias2.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "all_mias2.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "all_mias2.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "all_mias2.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "all_mias2.add(MaxPool2D(pool_size=(2, 2)))\n",
    "all_mias2.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "all_mias2.add(Dense(64, activation='relu'))\n",
    "all_mias2.add(Dropout(0.25))\n",
    "# flattening results\n",
    "all_mias2.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "all_mias2.add(Dense(3, activation='softmax'))\n",
    "# print summary\n",
    "all_mias2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(all_mias2, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set optmizer and learning rate\n",
    "adam = Adam(0.001)\n",
    "all_mias2.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=3000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = all_mias2.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = all_mias2.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = all_mias2.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                               hist.history['val_accuracy'], \n",
    "                               hist.history['loss'], \n",
    "                               hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter data to the final results dataframe\n",
    "results_all_mias2 = classification_report(expected, predicted, output_dict=True)\n",
    "# add entry to the final_results\n",
    "all_mias_malignant2 = results_all_mias2['1']\n",
    "all_mias_malignant2\n",
    "final_results.loc['all_bal'] = (accuracy,\n",
    "                                all_mias_malignant2['precision'], \n",
    "                                all_mias_malignant2['recall'], \n",
    "                                all_mias_malignant2['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "predictions = all_mias2.predict(test_data)\n",
    "wrong_predictions = []\n",
    "images = all_mias_bal.p_matrix\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_mias_bal.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=5, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {all_mias_bal.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.plot(kind='barh', figsize=(7, 9), legend={'reverse'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
